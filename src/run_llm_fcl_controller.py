# src/run_llm_fcl_controller.py

import argparse, time, copy, random
import numpy as np
import torch
from torch.utils.data import DataLoader, Subset
from torch import optim
from torchvision import datasets, transforms
import pandas as pd
import math

from src.model import build_resnet18
from src.fl import Client, Server
from src.strategies.replay import ReplayBuffer
from src.policy import Policy
from src.policy.lmss_api import lmss_decide_action_api
from src.agent_io import save_json
from src.agent_io import write_state_json, write_action_json, validate_action
from src.mock_agent import decide_action as mock_decide_action
import os, json
# run_llm_fcl_controller.py
from src._bootstrap_env import *  # sets TOKENIZERS_PARALLELISM=false early

# ---------------------------
# Controller v4 hyperparams
# ---------------------------
V4_LR_MIN, V4_LR_MAX = 1e-4, 2e-3
V4_REP_MIN, V4_REP_MAX = 0.20, 0.70
V4_DEADBAND = 0.003
V4_REP_STEP_HIGH = 0.10
V4_REP_STEP_LOW  = 0.05
V4_FORGET_THR    = 0.05
V4_DIV_THR       = 0.10
V4_EMA_ALPHA     = 0.30
V4_LR_BOOST      = 1.35
V4_LR_COOLDOWN   = 1.50
V4_CLIENT_LR_MIN, V4_CLIENT_LR_MAX = 0.8, 1.2
V4_ROLLBACK_THR  = 0.02         # absolute acc drop
V4_WARMUP_ROUNDS = 2


# --- SFT controller helper (local tiny model) ---
def _compact_state_for_sft(state):
    g = state["global"]
    keep = {
        "acc": float(round(g["acc"], 4)),
        "ema_loss": float(round(g["ema_loss"], 4)),
        "forget_mean": float(round(g["forget_mean"], 4)),
        "divergence": float(round(g["divergence"], 4)),
    }
    clients = []
    for c in state["clients"]:
        vloss = c["vloss"]
        if isinstance(vloss, float) and vloss != vloss:  # NaN
            vloss = None
        def _safe_float(x):
            try:
                x = float(x)
                # NaN check
                return None if (x != x) else x
            except Exception:
                return None

        clients.append({
            "id": int(c["id"]),
            "vloss": _safe_float(vloss),
            "vacc": _safe_float(c.get("vacc")),
            "new_batch_size": int(c["new_batch_size"]),
            "last_lr": _safe_float(c.get("last_lr")),
        })
    return {"global": keep, "clients": clients}

import re

def _balanced_json_from_text(s, anchor="ACTION:"):
    """
    Find JSON after anchor and repair common small-model errors:
    - missing quotes on keys: {aggregation: -> {"aggregation":
    - truncated JSON: add missing ] and } when possible
    """
    if anchor in s:
        s = s.split(anchor)[-1]

    start_idx = s.find("{")
    if start_idx == -1:
        return "{}"

    s = s[start_idx:].strip()

    # Repair 1: add quotes to unquoted keys
    s = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', s)

    # Repair 2: find balanced end
    depth = 0
    final_idx = len(s)
    for i, ch in enumerate(s):
        if ch == "{":
            depth += 1
        elif ch == "}":
            depth -= 1
            if depth == 0:
                final_idx = i + 1
                break

    candidate = s[:final_idx]

    # Repair 3: if truncated, best-effort close
    if depth > 0:
        candidate = candidate.rstrip().rstrip(",")
        if "[" in candidate and "]" not in candidate:
            candidate += "]"
        candidate += ("}" * depth)

    return candidate

_sft_cache = {"tok": None, "mdl": None}

def sft_decide_action(state, model_dir="sft_model_distilgpt2", fewshot=True):
    from transformers import AutoTokenizer, AutoModelForCausalLM

    # lazy load (keeps it fast across rounds)
    if _sft_cache["tok"] is None:
        tok = AutoTokenizer.from_pretrained(model_dir)
        mdl = AutoModelForCausalLM.from_pretrained(model_dir)

        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        mdl = mdl.to(device)
        print("âœ… SFT model device:", next(mdl.parameters()).device, flush=True)

        tok.pad_token = tok.eos_token
        _sft_cache["tok"], _sft_cache["mdl"] = tok, mdl
    else:
        tok, mdl = _sft_cache["tok"], _sft_cache["mdl"]

    s_small = _compact_state_for_sft(state)
    num_clients = len(state["clients"])

    instruction = (
        f"TASK: Output ONE valid JSON object for an ACTION for {num_clients} clients.\n"
        f"CLIENT IDS: You MUST include exactly one entry for EACH client id 0..{num_clients-1}.\n"
        "OUTPUT RULES:\n"
        "- Output ONLY JSON. No text before or after.\n"
        "- Use ONLY the ACTION schema below.\n"
        "ACTION SCHEMA:\n"
        '{ "client_selection_k": <int>, "aggregation": {"method":"FedAvg"}, '
        '"client_params": ['
        '{"id":<int>,"replay_ratio":<float>,"lr_scale":<float>,"ewc_lambda":<float>},'
        ' ... ] }\n'
        "BOUNDS:\n"
        "- replay_ratio in [0.0, 0.7]\n"
        "- lr_scale in [0.5, 1.5]\n"
        "- ewc_lambda in [0.0, 10.0]\n"
        "IMPORTANT:\n"
        "- Do NOT output STATE.\n"
        "- Do NOT invent new client ids.\n"
    )

    demo = ""
    if fewshot:
        demo = (
            "EXAMPLE:\n"
            'STATE: {"global":{"acc":0.011,"ema_loss":4.73,"forget_mean":0.001,"divergence":0.001},'
            '"clients":[{"id":0,"vloss":4.68,"vacc":1.36,"new_batch_size":45,"last_lr":0.00012},'
            '{"id":1,"vloss":4.67,"vacc":1.34,"new_batch_size":45,"last_lr":0.00012}]}\n'
            "ACTION:\n"
            '{"client_selection_k":2,"aggregation":{"method":"FedAvg"},"client_params":['
            '{"id":0,"replay_ratio":0.5,"lr_scale":0.8,"ewc_lambda":0.0},'
            '{"id":1,"replay_ratio":0.5,"lr_scale":1.2,"ewc_lambda":0.0}]}\n\n'
        )

    # Force the model to start JSON immediately:
    prompt = (
        instruction + demo +
        f"STATE: {json.dumps(s_small, allow_nan=False)}\n\n"
        f"ACTION:\n{{\"client_selection_k\": {num_clients}, "
        f"\"aggregation\": {{\"method\": \"FedAvg\"}}, "
        f"\"client_params\": ["
    )

    inputs = tok(prompt, return_tensors="pt")
    inputs = {k: v.to(mdl.device) for k, v in inputs.items()}
    
    with torch.no_grad():
        gen = mdl.generate(
            **inputs,
            max_new_tokens=256,
            do_sample=False,
            pad_token_id=tok.eos_token_id,
            eos_token_id=tok.eos_token_id,
        )

    out_text = tok.decode(gen[0], skip_special_tokens=True)

    # Your prompt contains "ACTION:\n{", so extract from there
    raw_json = _balanced_json_from_text(out_text, anchor="ACTION:")

    # DEBUG (temporary): write what we saw if parse fails
    if raw_json == "{}":
        print(f"\n==== SFT PRODUCED NO JSON ====\nOUT_TEXT_TAIL:\n{out_text[-800:]}\n", flush=True)
        n_clients = len(state["clients"])
        return {
            "client_selection_k": n_clients,
            "aggregation": {"method": "FedAvg"},
            "client_params": [
                {"id": i, "replay_ratio": 0.5, "lr_scale": 1.0, "ewc_lambda": 0.0}
                for i in range(n_clients)
            ],
        }
    try:
        act = json.loads(raw_json)
    except json.JSONDecodeError as e:
        dump = (
            "\n==== SFT JSON DECODE FAILED ====\n"
            f"Error: {e}\n"
            f"RAW_JSON_HEAD: {raw_json[:400]}\n"
            f"RAW_JSON_TAIL: {raw_json[-400:]}\n"
            "\n---- OUT_TEXT_TAIL (last 800 chars) ----\n"
            f"{out_text[-800:]}\n"
        )
        print(dump, flush=True)

        n_clients = len(state["clients"])
        return {
            "client_selection_k": n_clients,
            "aggregation": {"method": "FedAvg"},
            "client_params": [
                {"id": i, "replay_ratio": 0.5, "lr_scale": 1.0, "ewc_lambda": 0.0}
                for i in range(n_clients)
            ],
        }

    # =========================
    # STEP 2.2: sanitize client ids + enforce exact 0..n-1
    # =========================
    n_clients = len(state["clients"])
    params = act.get("client_params", [])
    by_id = {}
    for p in params:
        try:
            cid = int(p.get("id"))
        except Exception:
            continue
        if 0 <= cid < n_clients and cid not in by_id:
            by_id[cid] = p

    fixed = []
    for cid in range(n_clients):
        p = by_id.get(cid, {"id": cid})
        fixed.append({
            "id": cid,
            "replay_ratio": float(p.get("replay_ratio", 0.5)),
            "lr_scale": float(p.get("lr_scale", 1.0)),
            "ewc_lambda": float(p.get("ewc_lambda", 0.0)),
        })

    act["client_selection_k"] = n_clients
    act["aggregation"] = {"method": "FedAvg"}
    act["client_params"] = fixed

    # Your original checks (keep them)
    if "client_selection_k" not in act:
        raise RuntimeError(f"SFT action missing client_selection_k: {act}")
    if "client_params" not in act or not isinstance(act["client_params"], list) or len(act["client_params"]) == 0:
        raise RuntimeError(f"SFT action has empty/missing client_params: {act}")

    return act

# ---------------------------
# Seeding helpers
# ---------------------------
GLOBAL_SEED = 42
def seed_worker(worker_id: int):
    import numpy as _np, random as _random
    _np.random.seed(GLOBAL_SEED + worker_id)
    _random.seed(GLOBAL_SEED + worker_id)

def set_seeds(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# ---------------------------
# Eval helpers
# ---------------------------
def evaluate(model, device, test_loader):
    model.eval()
    correct, total = 0, 0
    n_classes = 100
    hits = np.zeros(n_classes, dtype=np.int64)
    counts = np.zeros(n_classes, dtype=np.int64)
    with torch.no_grad():
        for x, y in test_loader:
            x, y = x.to(device), y.to(device)
            pred = model(x).argmax(1)
            correct += (pred == y).sum().item()
            total += y.numel()
            for c in range(n_classes):
                mask = (y == c)
                if mask.any():
                    counts[c] += mask.sum().item()
                    hits[c] += (pred[mask] == c).sum().item()
    acc = correct / max(1, total)
    per_class_recall = np.array(
        [(hits[c] / counts[c]) if counts[c] > 0 else 0.0 for c in range(n_classes)],
        dtype=np.float32,
    )
    return acc, per_class_recall

def evaluate_loss(model, device, loader):
    model.eval()
    crit = torch.nn.CrossEntropyLoss()
    total_loss, n = 0.0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            logits = model(x)
            total_loss += float(crit(logits, y).item()) * y.size(0)
            n += y.size(0)
    return total_loss / max(1, n)

# ---------------------------
# Main
# ---------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--clients", type=int, default=4)
    ap.add_argument("--alpha", type=float, default=0.2)
    ap.add_argument("--epochs", type=int, default=20)
    ap.add_argument("--rounds", type=int, default=7)
    ap.add_argument("--batch_size", type=int, default=256)
    ap.add_argument("--lr", type=float, default=1e-4)
    ap.add_argument("--subset_per_client", type=int, default=-1, help="use -1 for all data")
    ap.add_argument("--device", type=str, default="cuda")
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--log_interval", type=int, default=50)
    ap.add_argument("--split_mode", choices=["equal"], default="equal")
    ap.add_argument("--val_size", type=int, default=5000)
    ap.add_argument("--cl_batches", type=int, default=7)
    ap.add_argument("--num_workers", type=int, default=4)
    ap.add_argument("--optimizer", choices=["adam","sgd"], default="adam")
    ap.add_argument("--early_patience", type=int, default=5)
    ap.add_argument("--tag", type=str, default="controller_v4")
    ap.add_argument("--controller", choices=["v4", "mock", "fixed", "sft", "lmss_api", "lmss_local"], default="v4")
    ap.add_argument("--lmss_model", type=str, default="Qwen/Qwen2.5-0.5B-Instruct")
    args = ap.parse_args()

    controller_name_map = {
        "v4": "ControllerV4",
        "mock": "Mock",
        "fixed": "Fixed",
        "sft": "SFT_v0",
        "lmss_api": "LMSS_API",
        "lmss_local": "LMSS_LOCAL",
    }

    controller_name = controller_name_map.get(args.controller, args.controller)
    
    set_seeds(args.seed)
    # safe device selection with fallback for mac (no CUDA)
    if args.device == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
        elif getattr(torch.backends, "mps", None) is not None and torch.backends.mps.is_available():
            device = torch.device("mps")
        else:
            device = torch.device("cpu")
    else:
        try:
            if args.device == "cuda" and not torch.cuda.is_available():
                raise RuntimeError("CUDA not available")
            if args.device == "mps" and not (getattr(torch.backends, "mps", None) and torch.backends.mps.is_available()):
                raise RuntimeError("MPS not available")
            device = torch.device(args.device)
        except Exception as e:
            print(f"Warning: requested device '{args.device}' not available ({e}); falling back to cpu", flush=True)
            device = torch.device("cpu")
    print(f"Using device: {device}", flush=True)

    
    global GLOBAL_SEED
    GLOBAL_SEED = args.seed

    g = torch.Generator()
    g.manual_seed(args.seed)

    # Transforms
    tf_train = transforms.Compose([
        transforms.Resize(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),
    ])
    tf_test = transforms.Compose([
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),
    ])

    # Data
    trainset_full = datasets.CIFAR100(root="./data", train=True,  download=True, transform=tf_train)
    testset       = datasets.CIFAR100(root="./data", train=False, download=True, transform=tf_test)

    total_train = len(trainset_full)  # 50_000
    val_size = args.val_size          # 5_000
    train_size = total_train - val_size

    train_subset, val_subset = torch.utils.data.random_split(
        trainset_full, [train_size, val_size], generator=g
    )
    train_indices = np.array(train_subset.indices, dtype=np.int64)
    val_indices   = np.array(val_subset.indices, dtype=np.int64)

    valset = Subset(trainset_full, val_indices)
    val_loader = DataLoader(valset, batch_size=256, shuffle=False,
                            num_workers=args.num_workers, pin_memory=True)
    test_loader = DataLoader(testset, batch_size=256, shuffle=False,
                             num_workers=args.num_workers, pin_memory=True)

    print(f"[Split] train={len(train_indices)} val={len(val_indices)} test={len(testset)}", flush=True)

    # Split among clients (equal-size)
    rng = np.random.RandomState(args.seed)
    perm = rng.permutation(train_indices)
    sizes = [len(perm) // args.clients] * args.clients
    for i in range(len(perm) % args.clients):
        sizes[i] += 1
    splits, start = [], 0
    for s in sizes:
        splits.append(perm[start:start+s].tolist())
        start += s

    # Optional subsample per client
    if args.subset_per_client and args.subset_per_client > 0:
        splits = [idxs[:args.subset_per_client] for idxs in splits]

    for i, idxs in enumerate(splits):
        print(f"[Split] client {i}: {len(idxs)} images", flush=True)

    # Build CL schedule: initial ~0.466 + even splits
    def make_cl_batches(indices, num_batches=7, seed=42):
        rng_local = np.random.RandomState(seed)
        idx = np.array(indices, dtype=np.int64)
        rng_local.shuffle(idx)
        init = int(round(0.466 * len(idx)))
        init = max(1, min(len(idx) - (num_batches - 1), init))
        first = idx[:init]
        rem = idx[init:]
        if num_batches <= 1:
            return [idx.tolist()]
        per = len(rem) // (num_batches - 1)
        chunks = [rem[i*per:(i+1)*per] for i in range(num_batches - 2)]
        chunks.append(rem[(num_batches - 2)*per:])
        return [first.tolist()] + [c.tolist() for c in chunks]

    cl_schedule, cl_rows = [], []
    for cid, idxs in enumerate(splits):
        batches = make_cl_batches(idxs, num_batches=args.cl_batches, seed=args.seed + cid)
        cl_schedule.append(batches)
        sizes = [len(b) for b in batches]
        print(f"[CL] client {cid}: {sizes} (sum={sum(sizes)})", flush=True)
        for i, b in enumerate(batches, start=1):
            cl_rows.append({"run_id": "", "client": cid, "cl_batch": i, "size": len(b)})

    # Init clients
    clients = []
    for cid, idx in enumerate(splits):
        subset = Subset(trainset_full, idx)
        loader = DataLoader(
            subset,
            batch_size=args.batch_size,
            shuffle=True,
            num_workers=args.num_workers,
            pin_memory=True,
            worker_init_fn=seed_worker,
            generator=g,
        )
        model = build_resnet18(100).to(device)
        if args.optimizer == "adam":
            opt = optim.Adam(model.parameters(), lr=args.lr, weight_decay=0.0)
        else:
            opt = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)
        replay = ReplayBuffer(capacity=2000)
        clients.append(Client(cid, model, opt, loader, device=device, replay=replay,
                              val_loader=val_loader, early_patience=args.early_patience))

        if cid == 0:
            trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)
            total = sum(p.numel() for p in model.parameters())
            print(f"Trainable params: {trainable:,}/{total}", flush=True)

    print("âœ… Client 0 model device:", next(clients[0].model.parameters()).device, flush=True)

    # Server / Policy
    server = Server(device=device)
    policy = Policy()

    print("[DEBUG] Before initial FedAvg", flush=True)

    # Initial global model + metrics
    print("[DEBUG] Before initial FedAvg", flush=True)
    global_model = server.average([c.model for c in clients])
    print("[DEBUG] After initial FedAvg", flush=True)

    acc, per_class = evaluate(global_model, device, test_loader)
    print("[DEBUG] After initial evaluate()", flush=True)

    best_recall = per_class.copy()
    forgetting = np.zeros_like(per_class)
    global_loss = evaluate_loss(global_model, device, test_loader)
    ema_loss = global_loss
    div_norm = 0.0

    # --- comm accounting: approximate model size in bytes (FP32 unless changed) ---
    def _model_num_params_bytes(model) -> int:
        total = 0
        for p in model.parameters():
            total += p.numel() * (4 if p.dtype in (torch.float32, torch.int32) else 2 if p.dtype == torch.float16 else 4)
        return total

    MODEL_BYTES = _model_num_params_bytes(global_model)
    print(f"[comm] MODEL_BYTES â‰ˆ {MODEL_BYTES:,}")

    print(f"[Round -1] acc={acc:.3f}", flush=True)

    # Local best/rollback tracking (no Server.save_state)
    best_state = copy.deepcopy(global_model.state_dict())
    best_global_acc = float(acc)
    best_hp = {"lr": args.lr, "replay_ratio": 0.50, "notes": "init (paper defaults)"}
    best_round = -1
    rollback_flag = False
    rollback_round = -1
    last_acc = acc
    last_hp = copy.deepcopy(best_hp)

    run_id = time.strftime("%Y%m%d-%H%M%S")
    # Fill run_id into CL rows for traceability
    for row in cl_rows:
        row["run_id"] = run_id

    run_logs, round_logs = [], []

    io_root = os.path.join("runs", run_id)
    os.makedirs(io_root, exist_ok=True)

    def _build_state(round_id, acc_global, loss_global, ema_loss, forget_mean, forget_max, divergence, bytes_last_round, client_snapshots):
        return {
            "round_id": int(round_id),
            "global": {
                "acc": float(acc_global),
                "loss": float(loss_global),
                "ema_loss": float(ema_loss),
                "forget_mean": float(forget_mean),
                "forget_max": float(forget_max),
                "divergence": float(divergence),
                "bytes_last_round": int(bytes_last_round),
            },
            "clients": client_snapshots,  # list of dicts with vloss, vacc, last_lr, last_replay_ratio, last_ewc_lambda, etc.
        }

    def _safe_last_lr(c, fallback_lr):
        try:
            return float(c.optimizer.param_groups[0]["lr"])
        except Exception:
            return float(fallback_lr)
        
    # ---------------------------
    # Training rounds
    # ---------------------------
    bytes_last_round = 0  # carried into the next round's state
    bytes_cum = 0
    aulc_running = 0.0
    # --- metrics accumulators ---
    acc_hist = []            # for AULC
    comm_bytes_cum = 0       # cumulative comm

    for r in range(args.rounds):
        acc_delta = float(acc - last_acc)

        # --- Build and write STATE JSON (once, at round start) ---
        client_snaps = []
        for c in clients:
            # robust last_lr: if optimizer exists use it, else fallback to last chosen HP or CLI LR
            if hasattr(c, "optimizer") and getattr(c.optimizer, "param_groups", None):
                _lr_snapshot = float(c.optimizer.param_groups[0]["lr"])
            else:
                _lr_snapshot = float(last_hp.get("lr", args.lr))

            # new batch size for THIS round for this client (size of incoming CL chunk)
            batches = cl_schedule[c.cid]
            nb = len(batches[r]) if r < len(batches) else len(batches[-1])

            client_snaps.append({
                "id": int(c.cid),
                "vloss": float(getattr(c, "_last_vloss", float("nan"))),
                "vacc": float(getattr(c, "_last_vacc", float("nan"))),
                "new_batch_size": int(nb),
                "replay_capacity": int(getattr(getattr(c, "replay", None), "capacity", 2000)),
                "last_lr": _lr_snapshot,
                "last_replay_ratio": float(last_hp.get("replay_ratio", 0.50)),
                "last_ewc_lambda": float(getattr(c, "_last_ewc_lambda", 0.0)),
            })

        state = {
            "round_id": int(r),
            "global": {
                "acc": float(acc),
                "last_acc": float(last_acc),
                "loss": float(global_loss),
                "ema_loss": float(ema_loss),
                "forget_mean": float(np.mean(forgetting)) if forgetting is not None else 0.0,
                "forget_max": float(np.max(forgetting)) if forgetting is not None else 0.0,
                "divergence": float(div_norm),
                "bytes_last_round": int(bytes_last_round),
                "bytes_cum": int(bytes_cum),
            },
            "clients": client_snaps,
        }
        write_state_json(io_root, r, state)

        # =========================================================
        # Decide action ONCE (by controller) -> validate ONCE
        # =========================================================
        if args.controller == "sft":
            # SFT: the tiny local LM returns JSON; we validate & clamp it.
            print(f"[DEBUG] Calling SFT controller at round {r}", flush=True)
            raw = sft_decide_action(state, model_dir="models/sft_distilgpt2_v2")
            action = validate_action(raw, n_clients=len(clients), policy_source="SFT_v2")
            hp_lr = float(args.lr)
            rep = float(action["client_params"][0]["replay_ratio"]) if action["client_params"] else 0.50
            hp_notes = "SFT_v2"

        elif args.controller == "mock":
            # Mock: synthetic policy for plumbing / dataset creation
            raw = mock_decide_action(state, n_clients=len(clients))
            action = validate_action(raw, n_clients=len(clients), policy_source="Mock")
            hp_lr = float(args.lr)
            rep = float(action["client_params"][0]["replay_ratio"]) if action["client_params"] else 0.50
            hp_notes = "Mock"

        elif args.controller == "lmss_api":
            # LMSS via API: LLM selects strategy_id, we expand deterministically
            raw = lmss_decide_action_api(state, compact_state_fn=_compact_state_for_sft, model="gpt-4o-mini")
            action = validate_action(raw, n_clients=len(clients), policy_source=raw.get("policy_source", "LMSS_API"))
            hp_lr = float(raw.get("lr", args.lr))
            rep = float(action["client_params"][0]["replay_ratio"]) if action["client_params"] else 0.50
            hp_notes = raw.get("policy_source", "LMSS_API")

        elif args.controller == "lmss_local":
            from src.policy.lmss_local import lmss_decide_action_local

            raw = lmss_decide_action_local(
                state,
                compact_state_fn=_compact_state_for_sft,
                model_name=getattr(args, "lmss_model", "Qwen/Qwen2.5-0.5B-Instruct"),
            )
            action = validate_action(raw, n_clients=len(clients), policy_source=raw.get("policy_source", "LMSS_LOCAL"))
            hp_lr = float(raw.get("lr", args.lr))
            rep = float(action["client_params"][0]["replay_ratio"]) if action["client_params"] else 0.50
            hp_notes = raw.get("policy_source", "LMSS_LOCAL")


        elif args.controller == "v4":
            # Controller V4: compute hp (lr/rep) from simple signals
            dacc = float(acc - last_acc)
            F_t  = float(np.mean(forgetting)) if forgetting is not None else 0.0
            L_ema = float(ema_loss)
            div   = float(div_norm)

            if rollback_flag:
                lr = float(best_hp["lr"])
                rep = float(best_hp["replay_ratio"])
                notes = [f"ROLLBACK(r{rollback_round}â†’best r{best_round})"]
                rollback_flag = False

            elif r < V4_WARMUP_ROUNDS:
                lr, rep = float(args.lr), 0.50
                notes = ["warmup (fixed defaults)"]

            else:
                lr, rep = float(last_hp["lr"]), float(last_hp["replay_ratio"])
                notes = ["policy_v4"]

                if abs(dacc) < V4_DEADBAND:
                    notes.append(f"deadband(|dacc|<{V4_DEADBAND})")
                else:
                    if F_t > V4_FORGET_THR or div > V4_DIV_THR:
                        rep += V4_REP_STEP_HIGH
                        notes.append("replayâ†‘ (forget/div high)")
                    else:
                        rep -= V4_REP_STEP_LOW
                        notes.append("replayâ†“ (forget low)")

                    if dacc < -V4_DEADBAND:
                        lr /= V4_LR_COOLDOWN
                        notes.append("lrâ†“ (dacc<0)")
                    elif dacc > V4_DEADBAND and L_ema > 1.5:
                        lr *= V4_LR_BOOST
                        notes.append("lrâ†‘ (loss high & improving)")

            # clamp hp
            lr  = max(V4_LR_MIN,  min(V4_LR_MAX,  lr))
            rep = max(V4_REP_MIN, min(V4_REP_MAX, rep))
            notes.append(f"clamped(lrâˆˆ[{V4_LR_MIN},{V4_LR_MAX}], repâˆˆ[{V4_REP_MIN:.2f},{V4_REP_MAX:.2f}])")

            # build per-client scales by vloss rank (higher loss â†’ lower scale)
            vlosses = []
            for c in clients:
                v = getattr(c, "_last_vloss", None)
                vlosses.append(float(v) if v is not None and not np.isnan(v) else float(global_loss))
            vl_min, vl_max = float(np.min(vlosses)), float(np.max(vlosses))
            rng_v = max(1e-8, vl_max - vl_min)

            # --- âœ… WARMUP FIX: force lr_scale=1.0 during warmup rounds ---
            if r < V4_WARMUP_ROUNDS:
                lr_scales = [1.0 for _ in clients]
                notes.append("warmup: lr_scale forced to 1.0")
            else:
                lr_scales = [
                    float(
                        max(
                            V4_CLIENT_LR_MIN,
                            min(
                                V4_CLIENT_LR_MAX,
                                V4_CLIENT_LR_MIN
                                + (1.0 - ((vlosses[i] - vl_min) / rng_v))
                                * (V4_CLIENT_LR_MAX - V4_CLIENT_LR_MIN),
                            ),
                        )
                    )
                    for i in range(len(clients))
                ]

            candidate = {
                "client_selection_k": len(clients),
                "aggregation": {"method": "FedAvg"},
                "client_params": [
                    {
                        "id": int(c.cid),
                        "replay_ratio": float(rep),
                        "lr_scale": float(lr_scales[i]),
                        "ewc_lambda": float(getattr(c, "_last_ewc_lambda", 0.0)),
                    }
                    for i, c in enumerate(clients)
                ],
            }

            action = validate_action(candidate, n_clients=len(clients), policy_source="ControllerV4")
            hp_lr = float(lr)
            hp_notes = " | ".join(notes)
            
        elif args.controller == "fixed":
            # fixed (paper CL defaults)
            candidate = {
                "client_selection_k": len(clients),
                "aggregation": {"method": "FedAvg"},
                "client_params": [
                    {"id": int(c.cid), "replay_ratio": 0.50, "lr_scale": 1.0, "ewc_lambda": 0.0}
                    for c in clients
                ],
            }
            action = validate_action(candidate, n_clients=len(clients), policy_source="Fixed")
            hp_lr = float(args.lr)
            rep = 0.50
            hp_notes = "fixed (paper CL default)"
        else:
            raise ValueError(f"Unknown controller: {args.controller}")

        # =========================================================
        # Apply the validated ACTION uniformly (HP + per-client LR)
        # =========================================================
        # replay ratio comes from first client entry
        rep_from_action = (
            float(action["client_params"][0]["replay_ratio"])
            if action.get("client_params") else 0.50
        )
        hp = {"lr": hp_lr, "replay_ratio": rep_from_action, "notes": hp_notes}

        cid2scale = {int(p["id"]): float(p.get("lr_scale", 1.0)) for p in action.get("client_params", [])}
        for c in clients:
            scale = cid2scale.get(int(c.cid), 1.0)
            for pg in c.optimizer.param_groups:
                pg["lr"] = hp["lr"] * scale
            c._last_lr_scale = float(scale)

        # policy line for logs
        F_t_print = float(np.mean(forgetting)) if forgetting is not None else 0.0
        print(
            f"[Policy r={r}] acc={acc:.3f} dacc={acc_delta:+.3f} F_t={F_t_print:.3f} Div={div_norm:.3f} "
            f"-> lr={hp['lr']:.5f}, replay={hp['replay_ratio']:.2f} ({hp['notes']})",
            flush=True,
        )

        # persist chosen hp for next round snapshots
        last_hp = {"lr": hp["lr"], "replay_ratio": hp["replay_ratio"], "notes": hp["notes"]}

        # ---- Write ACTION JSON exactly once per round ----
        write_action_json(io_root, r, action, policy_source=action.get("policy_source", controller_name))

        # =========================================================
        # Local training per client
        # =========================================================
        for c in clients:
            batches = cl_schedule[c.cid]
            if r < len(batches):
                batch_indices = batches[r]
                batch_id = r
            else:
                batch_indices = batches[-1]
                batch_id = len(batches) - 1

            c.loader = DataLoader(
                Subset(trainset_full, batch_indices),
                batch_size=args.batch_size,
                shuffle=True,
                num_workers=args.num_workers,
                pin_memory=True,
                worker_init_fn=seed_worker,
                generator=g,
            )

            print(f"[Round {r}] client {c.cid}: CL batch {batch_id+1}/{len(batches)} "
                  f"(new={len(batch_indices)}; replayâ‰ˆ{hp['replay_ratio']:.2f}, LR_scale={c._last_lr_scale:.2f})",
                  flush=True)

            for e in range(args.epochs):
                avg_loss, epoch_acc, stop = c.train_one_epoch(
                    replay_ratio=hp["replay_ratio"],
                    epoch=e,
                    total_epochs=args.epochs,
                    log_interval=args.log_interval,
                )
                run_logs.append({
                    "run_id": run_id, "tag": args.tag, "round": r, "client": c.cid,
                    "epoch": e + 1,
                    "lr": float(c.optimizer.param_groups[0]["lr"]),
                    "replay_ratio": float(hp["replay_ratio"]),
                    "cl_batch": batch_id + 1,
                    "cl_batch_size": len(batch_indices),
                    "train_loss": float(avg_loss),
                    "train_acc": float(epoch_acc),
                    "val_loss": float(getattr(c, "_last_vloss", float("nan"))),
                    "val_acc": float(getattr(c, "_last_vacc", float("nan"))),
                })
                if stop:
                    print(f"[Client {c.cid}] Early stopping (patience {c.early_patience})", flush=True)
                    break

        # ---- Divergence (before FedAvg) ----
        with torch.no_grad():
            def flat_params(m: torch.nn.Module):
                return torch.cat([p.detach().float().view(-1).to(device) for p in m.parameters()])
            g_flat = flat_params(global_model)
            dists = []
            for c in clients:
                c_flat = flat_params(c.model)
                dists.append(torch.norm(c_flat - g_flat, p=2).item())
            if len(dists) > 1:
                div_norm = float(np.std(dists) / (np.median(dists) + 1e-8))
            else:
                div_norm = 0.0

        # ---- Aggregate & evaluate ----
        global_model = server.average([c.model for c in clients])
        last_acc = float(acc)
        acc, per_class = evaluate(global_model, device, test_loader)

        # running mean AULC up to round r
        aulc_running = ((aulc_running * r) + float(acc)) / max(1, (r + 1))

        # ---- Rollback check ----
        if acc < best_global_acc - V4_ROLLBACK_THR:
            global_model.load_state_dict(best_state)
            acc, per_class = evaluate(global_model, device, test_loader)
            forgetting = np.maximum(0.0, best_recall - per_class)
            print(
                f"[ðŸ”¥ ROLLBACK r{r}] drop detected. Reverted to best (r{best_round}) acc={best_global_acc:.3f}",
                flush=True,
            )
            rollback_flag = True
            rollback_round = r
        else:
            rollback_flag = False

        # ---- Update best state ----
        if acc > best_global_acc:
            best_global_acc = float(acc)
            best_state = copy.deepcopy(global_model.state_dict())
            best_hp = copy.deepcopy(hp)
            best_round = r

        # ---- Update loss/EMA/forgetting ----
        global_loss = evaluate_loss(global_model, device, test_loader)
        ema_loss = V4_EMA_ALPHA * global_loss + (1.0 - V4_EMA_ALPHA) * ema_loss
        forgetting = np.maximum(0.0, best_recall - per_class)
        best_recall = np.maximum(best_recall, per_class)

        # scalar forgetting metrics for logging/reward
        forget_mean_val = float(np.mean(forgetting)) if forgetting is not None else 0.0
        forget_max_val  = float(np.max(forgetting))  if forgetting is not None else 0.0

        # ---- Comm bytes for this round (used next round) ----
        model_size_bytes = sum(p.numel() for p in global_model.parameters()) * 4  # float32
        bytes_last_round = model_size_bytes * 2 * len(clients)  # up + down
        bytes_cum += int(bytes_last_round)
        print(f"[round {r}] AULC={aulc_running:.4f} | ACC={acc:.4f} | COMM_round={bytes_last_round:,} | COMM_cum={bytes_cum:,}")

        # ---- Round summary log ----
        round_logs.append({
            "run_id": run_id, "tag": args.tag, "round": r,
            "global_acc": float(acc),

            "lr": float(hp["lr"]),
            "replay_ratio": float(hp["replay_ratio"]),
            "notes": hp.get("notes", ""),

            "global_loss": float(global_loss),
            "ema_loss": float(ema_loss),

            # forgetting metrics
            "forget_mean": float(forget_mean_val),
            "forget_max": float(forget_max_val),

            # stability / divergence
            "divergence": float(div_norm),

            # best seen and rollback flag
            "best_acc_so_far": float(best_global_acc),
            "was_rollback": bool(rollback_flag),

            # communication + AULC
            "comm_bytes_round": int(bytes_last_round),
            "comm_bytes_cum": int(bytes_cum),
            "aulc_running": float(aulc_running),
        })
        
        print(f"[Round {r}] acc={acc:.3f} (best={best_global_acc:.3f})", flush=True)

    # ---------------------------
    # Write CSVs
    # ---------------------------
    pd.DataFrame(run_logs).to_csv(f"fcl_run_results_{run_id}_{args.tag}.csv", index=False)
    pd.DataFrame(round_logs).to_csv(f"fcl_run_summary_{run_id}_{args.tag}.csv", index=False)
    pd.DataFrame(cl_rows).to_csv(f"fcl_run_cl_batches_{run_id}_{args.tag}.csv", index=False)
    print("âœ“ Wrote CSVs:",
          f"fcl_run_results_{run_id}_{args.tag}.csv,",
          f"fcl_run_summary_{run_id}_{args.tag}.csv,",
          f"fcl_run_cl_batches_{run_id}_{args.tag}.csv", flush=True)


if __name__ == "__main__":
    main()